<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vision | Zhenbang LI</title>
    <link>https://example.com/tag/vision/</link>
      <atom:link href="https://example.com/tag/vision/index.xml" rel="self" type="application/rss+xml" />
    <description>Vision</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language>
    <image>
      <url>https://example.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Vision</title>
      <link>https://example.com/tag/vision/</link>
    </image>
    
    <item>
      <title>Human pose and pose similarity estimation based on passive BLE beacon triggering</title>
      <link>https://example.com/project/graduate_design/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/graduate_design/</guid>
      <description>&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;The collection of human kinetic energy has great potential for applications in fields such as the Internet of Things and Human-computer Interaction, and its energy conversion mechanisms, information processing processes and related applications have been explored to some extent. Meanwhile, lightweight human detection models have been applied in the field of sports and health. However, current research has few cases of using motion energy harvesting-based Bluetooth beacons to trigger vision systems. This type of system has the advantages of low data volume, high critical information density, and low power consumption. Its construction process, application scenarios, advantages and reliability are in the stage of exploration. Based on this, this graduation design takes the key point recognition of human pose as the target task, builds a Bluetooth beacon-triggered vision capture system powered by motion energy, deploys a lightweight pose detection model MoveNet, tests various detection scenarios such as variable frame rate sequence pose detection, and explores the post-processing process of pose similarity detection represented by skeleton-oriented cosine similarity. On this basis, the specific application scenarios of the system in fitness and entertainment, industrial security and other fields are further discussed to provide a certain basis for the subsequent related research.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Plenoptic Stages (Light Stages) in Deemos Technologies and ShanghaiTech MARS lab</title>
      <link>https://example.com/project/stage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/stage/</guid>
      <description>&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Systems that can generate self-defined gradient illumination patterns and synchronize with camera systems
to acquire visual data sequences of objects, which can be used to generate pore-level facial models for
relighting use in the film industry, game industry, or light commercial use like video meetings. These systems can
work at high-speed rate up to 100hz, which is top-tier performance in the world.
Many Commercial Products and Paper have been developed based on the systems we developed.&lt;/p&gt;
&lt;h3 id=&#34;contribution&#34;&gt;Contribution&lt;/h3&gt;
&lt;p&gt;Worked as a 2 people team, developed and produced 2 generations of light stages.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Design and Engineering of the PCB, code, and structure of the Embedded light systems.&lt;/li&gt;
&lt;li&gt;Design and Engineering of the physical structures and nodes boards of the frame.&lt;/li&gt;
&lt;li&gt;Engineering of the data acquisition system.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;patent&#34;&gt;Patent&lt;/h3&gt;
&lt;p&gt;Three-dimensional reconstruction data acquisition system Espacenet link
WU DI; CAO RUIXIANG; LI ZHENBANG; YU JINGYI. 2022. Three-dimensional reconstruction data acquisition
system. CN. Patent Application CN215679031, filed May 1, 2021, and issued January 28, 2022. PATENT GRANT.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
